import json
import re
import os
import sys
import uuid
from urllib.parse import urlparse
from datetime import datetime, timedelta

from CloudflareBypasser import CloudflareBypasser
from DrissionPage import ChromiumPage, ChromiumOptions
from fastapi import FastAPI, HTTPException, Response, Body, Request, Depends, status
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Dict, Optional, Any, List, Union
import argparse

from pyvirtualdisplay import Display
import uvicorn
import atexit
import asyncio
import websockets
import json
from starlette.middleware.base import BaseHTTPMiddleware
import requests

# æ·»åŠ loguruç”¨äºæ—¥å¿—è®°å½•
from loguru import logger
# æ·»åŠ slowapiç”¨äºè¯·æ±‚é™é€Ÿ
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from slowapi.middleware import SlowAPIMiddleware

from models import AntiJsConfig, website_configs, init_db
from internal_api import router as internal_api_router, verify_credentials
from db import load_config, init_database_and_cache, get_db_session, get_redis_client, redis_prefix
import hashlib
# å¯¼å…¥å…±äº«æ¨¡å—
from shared import page_cache, browser_cache, cleanup_page


###yf
import random
proxys = [ x for x in os.environ.get('CHROME_PROXYS', "").strip().split(',') if x]
print(f"proxys: {proxys}")
if len(proxys) > 1:
    proxys = random.sample(proxys, len(proxys))

cnt = 0
def next_proxy():
    if len(proxys) == 0:
        return None
    global cnt
    cnt += 1
    return proxys[cnt % len(proxys)]
###yfend

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
LOG_DIR = os.path.join(os.getcwd(), "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# ç§»é™¤é»˜è®¤çš„loggeré…ç½®
logger.remove()
# æ·»åŠ æ§åˆ¶å°è¾“å‡º
logger.add(sys.stderr, level="INFO")
# æ·»åŠ æŒ‰å¤©å­˜å‚¨çš„æ–‡ä»¶æ—¥å¿—ï¼Œä¿ç•™7å¤©
logger.add(
    os.path.join(LOG_DIR, "anti_js_{time:YYYY-MM-DD}.log"),
    rotation="00:00",  # æ¯å¤©åˆå¤œè½®è½¬
    retention=timedelta(days=7),  # ä¿ç•™7å¤©çš„æ—¥å¿—
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss.SSS} [{level}][{extra[request_id]}] {message}",
    filter=lambda record: "request_id" in record["extra"]
)

# ä¸ºæ²¡æœ‰request_idçš„æ—¥å¿—æ·»åŠ å•ç‹¬çš„æ ¼å¼
logger.add(
    os.path.join(LOG_DIR, "system_{time:YYYY-MM-DD}.log"),
    rotation="00:00",  # æ¯å¤©åˆå¤œè½®è½¬
    retention=timedelta(days=7),  # ä¿ç•™7å¤©çš„æ—¥å¿—
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss.SSS} [{level}][SYSTEM] | {message}",
    filter=lambda record: "request_id" not in record["extra"]
)

# ç³»ç»Ÿæ—¥å¿—è¾…åŠ©å‡½æ•°
sys_logger = logger.bind(request_id="SYSTEM")

# è®¾ç½®è¯·æ±‚é™é€Ÿå™¨ï¼Œ1ç§’æœ€å¤š10ä¸ªè¯·æ±‚
limiter = Limiter(key_func=get_remote_address, default_limits=["10/second"])

# Check if running in Docker mode
# æ£€æµ‹æ“ä½œç³»ç»Ÿç±»å‹ï¼Œå¦‚æœæ˜¯Linuxåˆ™è®¾ç½®ä¸ºtrueï¼Œå¦åˆ™ä¸ºfalse
import platform
DOCKER_MODE = os.getenv("DOCKERMODE", "true" if platform.system() == "Linux" else "false").lower() == "true"

SERVER_PORT = int(os.getenv("SERVER_PORT", 8889))

# Chromium options arguments
arguments = [
    # "--remote-debugging-port=9222",  # Add this line for remote debugging
    "-no-first-run",
    "-force-color-profile=srgb",
    "-metrics-recording-only",
    "-password-store=basic",
    "-use-mock-keychain",
    "-export-tagged-pdf",
    "-no-default-browser-check",
    "-disable-background-mode",
    "-enable-features=NetworkService,NetworkServiceInProcess,LoadCryptoTokenExtension,PermuteTLSExtensions",
    "-disable-features=FlashDeprecationWarning,EnablePasswordsAccountStorage",
    "-deny-permission-prompts",
    "-disable-gpu",
    "-accept-lang=en-US",
    # "-incognito" # You can add this line to open the browser in incognito mode by default
]

# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ ç¯å¢ƒå˜é‡è®¾ç½®
# BROWSER_TYPE = os.getenv("BROWSER_TYPE", "edge").lower()  # é»˜è®¤ä½¿ç”¨ Edgeï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–
BROWSER_TYPE = os.getenv("BROWSER_TYPE", "chrome").lower()  # é»˜è®¤ä½¿ç”¨ Edgeï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–

# æ ¹æ®ç³»ç»ŸæŸ¥æ‰¾ Edge æµè§ˆå™¨è·¯å¾„
if BROWSER_TYPE == "edge":
    # åœ¨ä¸åŒç³»ç»Ÿä¸ŠæŸ¥æ‰¾ Edge æµè§ˆå™¨è·¯å¾„
    edge_paths = [
        "/usr/bin/microsoft-edge",
        "/usr/bin/microsoft-edge-stable",
        "/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge",
        "C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe",
        "C:\\Program Files\\Microsoft\\Edge\\Application\\msedge.exe"
    ]

    browser_path = None
    for path in edge_paths:
        if os.path.exists(path):
            browser_path = path
            break

    if not browser_path:
        sys_logger.warning("Microsoft Edge not found, using default browser")
        browser_path = "/usr/bin/google-chrome"  # é»˜è®¤è·¯å¾„
else:
    browser_path = "/usr/bin/google-chrome"

# è®¾ç½® DrissionPage ä½¿ç”¨ Edge æµè§ˆå™¨
if BROWSER_TYPE == "chrome":
    # ä½¿ç”¨ DrissionPage çš„é…ç½®æ–¹æ³•è®¾ç½® Edge
    from DrissionPage import ChromiumOptions
    co = ChromiumOptions()
    co.set_browser_path(browser_path)
    co.save()  # ä¿å­˜é…ç½®ï¼Œè¿™æ ·åç»­å¯åŠ¨éƒ½ä¼šä½¿ç”¨è¿™ä¸ªè®¾ç½®

app = FastAPI()

# æ·»åŠ è¯·æ±‚é™é€Ÿå¼‚å¸¸å¤„ç†
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
# æ·»åŠ è¯·æ±‚é™é€Ÿä¸­é—´ä»¶
app.add_middleware(SlowAPIMiddleware)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è‡ªå®šä¹‰ä¸­é—´ä»¶ï¼Œä¸ºæŒ‡å®šè·¯å¾„çš„å“åº”æ·»åŠ X-Request-IDå¤´éƒ¨


class RequestIDMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        # åªå¤„ç†/api/antijs/è·¯å¾„çš„è¯·æ±‚
        if request.url.path.startswith("/api/antijs/"):
            # ä»è¯·æ±‚å¯¹è±¡ä¸­è·å–request_idï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç”Ÿæˆä¸€ä¸ªæ–°çš„
            request_id = request.state.request_id if hasattr(request.state, "request_id") else str(uuid.uuid4())
            # ä¿å­˜åˆ°è¯·æ±‚å¯¹è±¡ä¸­
            request.state.request_id = request_id

            # å¤„ç†è¯·æ±‚
            response = await call_next(request)

            # åœ¨å“åº”å¤´ä¸­æ·»åŠ X-Request-ID
            response.headers["X-Request-ID"] = request_id
            return response

        # å¯¹äºå…¶ä»–è·¯å¾„çš„è¯·æ±‚ï¼Œæ­£å¸¸å¤„ç†
        return await call_next(request)


# æ·»åŠ è¯·æ±‚IDä¸­é—´ä»¶
app.add_middleware(RequestIDMiddleware)

# ç¡¬ç¼–ç Lark webhookåœ°å€ï¼ˆè¯·æ›¿æ¢ä¸ºå®é™…çš„webhookåœ°å€ï¼‰
lark_webhook_url = "https://open.feishu.cn/open-apis/bot/v2/hook/72345854-38fa-4c1c-89a9-197c0bcd26b8"

# å†…å­˜å­˜å‚¨ï¼šç”¨äºç»Ÿè®¡è¯·æ±‚å¤±è´¥æƒ…å†µ
# failure_times: {api_path: [timestamp1, timestamp2, ...]}  # å­˜å‚¨å¤±è´¥æ—¶é—´æˆ³åˆ—è¡¨
# alert_sent: {api_path: timestamp}  # å­˜å‚¨ä¸Šæ¬¡æŠ¥è­¦æ—¶é—´
failure_times_storage = {}
alert_sent_storage = {}

# å‘é€LarkæŠ¥è­¦æ¶ˆæ¯
async def send_lark_alert(url: str, params: Any, status_code: int, error_msg: str = None):
    """å‘é€LarkæŠ¥è­¦æ¶ˆæ¯"""
    global lark_webhook_url
    
    if not lark_webhook_url:
        return False
    
    try:
        # æ„å»ºæŠ¥è­¦æ¶ˆæ¯
        message = {
            "msg_type": "text",
            "content": {
                "text": f"âš ï¸ æ¥å£è¯·æ±‚å¤±è´¥æŠ¥è­¦\n\n"
                       f"æ¥å£URL: {url}\n"
                       f"çŠ¶æ€ç : {status_code}\n"
                       f"è¯·æ±‚å‚æ•°: {json.dumps(params, ensure_ascii=False, indent=2)}\n"
                       + (f"é”™è¯¯ä¿¡æ¯: {error_msg}\n" if error_msg else "")
                       + f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            }
        }
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥çš„requestsè°ƒç”¨ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        def send_request():
            response = requests.post(lark_webhook_url, json=message, timeout=5.0)
            return response
        
        response = await asyncio.to_thread(send_request)
        
        if response.status_code == 200:
            sys_logger.info(f"LarkæŠ¥è­¦å‘é€æˆåŠŸ: {url}")
            return True
        else:
            sys_logger.error(f"LarkæŠ¥è­¦å‘é€å¤±è´¥: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        sys_logger.error(f"å‘é€LarkæŠ¥è­¦æ—¶å‡ºé”™: {str(e)}")
        return False

# è¯·æ±‚å¤±è´¥ç»Ÿè®¡å’ŒæŠ¥è­¦ä¸­é—´ä»¶
class RequestFailureAlertMiddleware(BaseHTTPMiddleware):
    """ç»Ÿè®¡è¯·æ±‚å¤±è´¥æƒ…å†µå¹¶å‘é€æŠ¥è­¦çš„ä¸­é—´ä»¶ï¼ˆä½¿ç”¨å†…å­˜å­˜å‚¨ï¼‰"""
    
    async def dispatch(self, request: Request, call_next):
        # é¢„å…ˆè¯»å–å¹¶ä¿å­˜è¯·æ±‚ä½“ï¼ˆç”¨äºæŠ¥è­¦ï¼Œä¸å½±å“è·¯ç”±å¤„ç†ï¼‰
        request_body_data = None
        body_bytes = None
        
        if request.method in ["POST", "PUT", "PATCH"]:
            body_bytes = await request.body()
            request._body = body_bytes
            if body_bytes:
                try:
                    # å°è¯•è§£æä¸ºJSON
                    request_body_data = json.loads(body_bytes)
                except:
                    # å¦‚æœä¸æ˜¯JSONï¼Œä¿å­˜åŸå§‹å­—ç¬¦ä¸²ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
                    try:
                        request_body_data = body_bytes.decode('utf-8', errors='ignore')[:1000]
                    except:
                        request_body_data = "æ— æ³•è§£æè¯·æ±‚ä½“"
    
        # å¤„ç†è¯·æ±‚
        response = None
        try:
            response = await call_next(request)
            sys_logger.info("response", response, response.status_code)
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            # è¿™é‡Œæ•è·å¤„ç†å¼‚å¸¸ï¼Œä½ å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ—¥å¿—æˆ–å…¶ä»–å¤„ç†
            sys_logger.error(f"ä¸­é—´ä»¶å¤„ç†è¯·æ±‚å¼‚å¸¸: {str(e)}")
            response = JSONResponse(
                status_code=500,
                content={"code": 1, "msg": f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}"}
            )
        
        # åªç»Ÿè®¡é200çŠ¶æ€ç çš„è¯·æ±‚
        if response.status_code != 200:
            try:
                # è·å–è¯·æ±‚è·¯å¾„ä½œä¸ºæ¥å£æ ‡è¯†
                api_path = request.url.path
                current_time = datetime.now()
                current_timestamp = int(current_time.timestamp())
                
                # ä½¿ç”¨å†…å­˜å­˜å‚¨å¤±è´¥è®°å½•ï¼ˆæ»‘åŠ¨çª—å£ï¼Œ1å°æ—¶ï¼‰
                if api_path not in failure_times_storage:
                    failure_times_storage[api_path] = []
                
                # æ·»åŠ å½“å‰å¤±è´¥è®°å½•
                failure_times_storage[api_path].append(current_timestamp)
                
                # æ¸…ç†1å°æ—¶å‰çš„è®°å½•
                one_hour_ago = current_timestamp - 3600
                failure_times_storage[api_path] = [
                    ts for ts in failure_times_storage[api_path] if ts > one_hour_ago
                ]
                
                # è·å–1å°æ—¶å†…çš„å¤±è´¥æ¬¡æ•°
                failure_count = len(failure_times_storage[api_path])
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘é€æŠ¥è­¦
                if failure_count >= 10:
                    # æ£€æŸ¥24å°æ—¶å†…æ˜¯å¦å·²å‘é€è¿‡æŠ¥è­¦
                    last_alert_timestamp = alert_sent_storage.get(api_path)
                    should_alert = False
                    
                    if last_alert_timestamp:
                        # å¦‚æœè·ç¦»ä¸Šæ¬¡æŠ¥è­¦è¶…è¿‡24å°æ—¶ï¼Œå¯ä»¥å†æ¬¡æŠ¥è­¦
                        if current_timestamp - last_alert_timestamp >= 86400:  # 24å°æ—¶ = 86400ç§’
                            should_alert = True
                    else:
                        # ä»æœªå‘é€è¿‡æŠ¥è­¦ï¼Œå¯ä»¥å‘é€
                        should_alert = True
                    
                    if should_alert:
                        # æ„å»ºè¯·æ±‚å‚æ•°ç”¨äºæŠ¥è­¦
                        request_params = {
                            "method": request.method
                        }
                        
                        # æ·»åŠ æŸ¥è¯¢å‚æ•°
                        if request.query_params:
                            request_params["query_params"] = dict(request.query_params)
                        
                        # æ·»åŠ è¯·æ±‚ä½“ï¼ˆå¦‚æœå·²è¯»å–ï¼‰
                        if request_body_data is not None:
                            request_params["body"] = request_body_data
                        
                        # å‘é€æŠ¥è­¦
                        asyncio.create_task(
                            send_lark_alert(
                                url=str(request.url),
                                params=request_params,
                                status_code=response.status_code,
                                error_msg=None
                            )
                        )
                        
                        # è®°å½•æŠ¥è­¦æ—¶é—´
                        alert_sent_storage[api_path] = current_timestamp
                        sys_logger.warning(f"æ¥å£ {api_path} 1å°æ—¶å†…å¤±è´¥ {failure_count} æ¬¡ï¼Œå·²å‘é€æŠ¥è­¦")
                
            except Exception as e:
                # æŠ¥è­¦é€»è¾‘å‡ºé”™ä¸åº”è¯¥å½±å“æ­£å¸¸è¯·æ±‚
                sys_logger.error(f"è¯·æ±‚å¤±è´¥ç»Ÿè®¡ä¸­é—´ä»¶å‡ºé”™: {str(e)}")
        
        return response

# æ·»åŠ è¯·æ±‚å¤±è´¥ç»Ÿè®¡å’ŒæŠ¥è­¦ä¸­é—´ä»¶
app.add_middleware(RequestFailureAlertMiddleware)

# æ·»åŠ é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/static", StaticFiles(directory="static"), name="static")

# æ·»åŠ å†…éƒ¨APIè·¯ç”±
app.include_router(internal_api_router)

# Storage for page and browser instances
# ä¸å†è¿™é‡Œå®šä¹‰page_cacheå’Œbrowser_cacheï¼Œä»shared.pyå¯¼å…¥

# Pydantic model for the response


class CookieResponse(BaseModel):
    cookies: Dict[str, str]
    user_agent: str

# New ChromeRequest model


class ChromeRequest(BaseModel):
    debug: bool = Field(False)
    url: str = Field(...)            # Which page to enter first
    api_url: Optional[str] = Field(None)       # After entering the url, the api to call
    method: str = Field("GET")       # GET || POST
    body: Optional[str] = Field(None)
    headers: Dict[str, str] = Field(default_factory=dict)
    cookies: Dict[str, str]|str = Field(None) # init_cookieï¼Œ ç¬¬ä¸€æ¬¡æ‰ä¼šé‡ç½®
    reset_cookie: Dict[str, str]|str = Field(None) # æ¯æ¬¡éƒ½ä¼šé‡ç½®

    page_id: Optional[str] = Field(None)  # Page id, if passed will cache the page, enter resident, faster next visit. If not passed, will close the page
    # browser id, same as page_id, not passed use default window, passed will reuse window, if not exist create a new one
    browser_id: str = Field("default")

    snapshot: bool = Field(False)     # Whether to take a screenshot on failure, for debugging, do not use in production

    class Config:
        json_schema_extra = {
            "example-req": {
                "url": "https://blur.io/",
                "api_url": "https://core-api.prod.blur.io/v1/buy/0x05da517b1bf9999b7762eaefa8372341a1a47559",
                "headers": {
                    "<header-name>": "<header-value>",
                },
                "method": "POST",
                "body": "<api-url-request-body>",
                "cookies": {
                    "<cookie-name>": "<cookie-value>",
                },
                "page_id": "blur",
                "browser_id": "blur"
            },
        }

# Function to check if the URL is safe


def is_safe_url(url: str) -> bool:
    parsed_url = urlparse(url)
    ip_pattern = re.compile(
        r"^(127\.0\.0\.1|localhost|0\.0\.0\.0|::1|10\.\d+\.\d+\.\d+|172\.1[6-9]\.\d+\.\d+|172\.2[0-9]\.\d+\.\d+|172\.3[0-1]\.\d+\.\d+|192\.168\.\d+\.\d+)$"
    )
    hostname = parsed_url.hostname
    if (hostname and ip_pattern.match(hostname)) or parsed_url.scheme == "file":
        return False
    return True


# Function to bypass Cloudflare protection
def bypass_cloudflare(url: str, retries: int, log: bool, proxy: str = None) -> ChromiumPage:

    options = ChromiumOptions().auto_port()
    if DOCKER_MODE:
        options.set_argument("--remote-debugging-port=9222")
        options.set_argument("--no-sandbox")  # Necessary for Docker
        options.set_argument("--disable-gpu")  # Optional, helps in some cases
        options.set_argument("-deny-permission-prompts")  # æ‹’ç»æƒé™æç¤º
        options.set_paths(browser_path=browser_path).headless(False)
    else:
        options.set_argument("--auto-open-devtools-for-tabs", "true")  # æ‰“å¼€æ§åˆ¶å°
        options.set_paths(browser_path=browser_path).headless(False)

    if proxy:
        options.set_proxy(proxy)

    driver = ChromiumPage(addr_or_opts=options)
    try:
        driver.get(url)
        cf_bypasser = CloudflareBypasser(driver, retries, log)
        cf_bypasser.bypass()
        return driver
    except Exception as e:
        driver.quit()
        raise e


@app.get("/")
async def health():
    return JSONResponse(
                status_code=200,
                content={"msg": "ok"}
            )

# Endpoint to get cookies
@app.get("/cookies", response_model=CookieResponse)
async def get_cookies(url: str, retries: int = 5, proxy: str = None):
    if not is_safe_url(url):
        raise HTTPException(status_code=400, detail="Invalid URL")
    try:
        driver = bypass_cloudflare(url, retries, log, proxy)
        cookies = {cookie.get("name", ""): cookie.get("value", " ") for cookie in driver.cookies()}
        user_agent = driver.user_agent
        driver.quit()
        return CookieResponse(cookies=cookies, user_agent=user_agent)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Endpoint to get HTML content and cookies
@app.get("/html")
async def get_html(url: str, retries: int = 5, proxy: str = None):
    if not is_safe_url(url):
        raise HTTPException(status_code=400, detail="Invalid URL")
    try:
        driver = bypass_cloudflare(url, retries, log, proxy)
        html = driver.html
        cookies_json = {cookie.get("name", ""): cookie.get("value", " ") for cookie in driver.cookies()}
        response = Response(content=html, media_type="text/html")
        response.headers["cookies"] = json.dumps(cookies_json)
        response.headers["user_agent"] = driver.user_agent
        driver.quit()
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Get or create browser instance
def get_or_create_browser(browser_id: str, proxy: str = None, init_js: str = None) -> ChromiumPage:
    if browser_id in browser_cache:
        return browser_cache[browser_id]

    options = ChromiumOptions().auto_port()

    options.set_argument("--deny-permission-prompts")  # æ‹’ç»æƒé™æç¤º
    options.set_argument("--incognito")  # æ— ç—•æ¨¡å¼
    options.set_argument("--disable-extensions")  # ç¦ç”¨æ‰©å±•
    options.set_argument("--disable-dev-shm-usage")  # ç¦ç”¨/dev/shmä½¿ç”¨ï¼Œå¯ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œä½†å¯èƒ½ä¼šå½±å“æ€§èƒ½
    options.set_argument("--disable-features=AudioServiceOutOfProcess")  # ç¦ç”¨éŸ³é¢‘æœåŠ¡çš„å•ç‹¬è¿›ç¨‹ï¼Œæœ‰æ—¶å¯ä»¥è§£å†³ä¸éŸ³é¢‘ç›¸å…³çš„å´©æºƒ
    options.set_argument("--disable-renderer-backgrounding")  # ç¦ç”¨æ¸²æŸ“å™¨çš„åå°è¿è¡Œï¼Œå¯ä»¥å‡å°‘åå°æ¸²æŸ“è¿›ç¨‹çš„èµ„æºå ç”¨
    options.set_argument("--disable-logging")  # ç¦ç”¨æ—¥å¿—è®°å½•ï¼Œä»¥å‡å°‘æ—¥å¿—è®°å½•çš„èµ„æºæ¶ˆè€—
    options.set_argument("--disable-software-rasterizer")  # ç¦ç”¨è½¯ä»¶å…‰æ …åŒ–å™¨ã€‚è¿™ä¸ªå‚æ•°åœ¨ä¸€äº›æ˜¾å¡å…¼å®¹æ€§é—®é¢˜æ—¶å¯èƒ½æœ‰å¸®åŠ©
    options.set_argument("--disable-css-animations")  # ç¦ç”¨CSSåŠ¨ç”»
    options.set_argument("--disable-webrtc")  # ç¦ç”¨WebRTC
    options.set_argument("--disable-font-subpixel-positioning")  # ç¦ç”¨å­—ä½“å­åƒç´ æ¸²æŸ“
    options.set_argument("--no-pings")  # ç¦ç”¨è¶…é“¾æ¥å®¡è®¡
    options.set_argument("--disable-notifications")   # ç¦ç”¨é€šçŸ¥ç³»ç»Ÿ

    options.set_argument("--process-per-site")  # æ‰€æœ‰æ ‡ç­¾é¡µå…±äº«åŒä¸€ä¸ªæ¸²æŸ“è¿›ç¨‹
    options.set_argument("--disable-domain-reliability")  # ç¦ç”¨åŸŸå¯é æ€§ç›‘æ§
    options.set_argument("--disable-component-update")  # ç¦æ­¢ç»„ä»¶æ›´æ–°æ£€æŸ¥
    options.set_argument("--disable-default-apps")  # ç¦ç”¨é»˜è®¤åº”ç”¨è¯·æ±‚
    options.set_argument("--disable-background-networking")  # ç¦ç”¨é»˜è®¤åº”ç”¨è¯·æ±‚
    if DOCKER_MODE:
        options.set_argument("--no-sandbox")  # Docker ä¸­å¿…éœ€
        options.set_argument("--disable-web-security")  # æ²™ç®±å†²çªï¼šä½¿ç”¨ --no-sandbox æ—¶å¿…é¡»é…åˆ --disable-web-security
    options.set_argument("--disable-gpu")  # åœ¨æŸäº›æƒ…å†µä¸‹æœ‰å¸®åŠ©
    options.set_argument("--disable-crash-reporter")  # ç¦ç”¨å¥”æºƒæŠ¥å‘Š
    options.set_argument("--disable-breakpad")  # ç¦ç”¨å¥”æºƒæŠ¥å‘Š
    options.set_argument("--disable-client-side-phishing-detection")  # å…³é—­é’“é±¼æ£€æµ‹ï¼ˆå‡å°‘è¯·æ±‚ï¼‰

    # éŸ³è§†é¢‘ç›¸å…³è®¾ç½®
    options.set_argument("--autoplay-policy=no-user-gesture-required")  # å¼ºåˆ¶ç¦æ­¢è‡ªåŠ¨æ’­æ”¾ï¼ˆè¦†ç›–ç½‘ç«™è®¾ç½®ï¼‰
    options.set_argument("--disable-accelerated-video-decode")  # ç¦ç”¨è§†é¢‘ç¡¬ä»¶è§£ç 
    options.set_argument("--disable-accelerated-video-encode")  # ç¦ç”¨è§†é¢‘ç¡¬ä»¶ç¼–ç 
    options.set_argument("--mute-audio")  # é™éŸ³æ‰€æœ‰æ ‡ç­¾é¡µ

    # options.set_argument("--single-process")  # ä¸èƒ½å¼€ï¼Œå¼€äº†æœåŠ¡å™¨ç”¨ä¸äº†ã€‚å•è¿›ç¨‹æ¨¡å¼ï¼Œ# æ‰€æœ‰å†…å®¹è¿è¡Œåœ¨å•ä¸ªè¿›ç¨‹ï¼Œè¿›ç¨‹æ•°ä» 10+ å‡å°‘åˆ° 3-4 ä¸ªï¼Œå†…å­˜å ç”¨å‡å°‘ 40%-60% (ä» 800MB â†’ 300-500MB)ï¼Œæ ‡ç­¾é¡µå´©æºƒä¼šå¯¼è‡´æ•´ä¸ªæµè§ˆå™¨é€€å‡º
    options.set_argument("--no-zygote")  # ç¦ç”¨é¢„åŠ è½½æœºåˆ¶,å‡å°‘ 2 ä¸ª Zygote ç›¸å…³è¿›ç¨‹,å‡å°‘ 2 ä¸ª Zygote ç›¸å…³è¿›ç¨‹

    # options.set_argument("--remote-allow-origins=*")
    if DOCKER_MODE:
        # options.set_argument("--remote-debugging-port=9222")
        options.no_imgs()
        # æ³¨ï¼šä¸ç¡®å®šç»•è¿‡cloudflareæ˜¯å¦éœ€è¦headlessè®¾ä¸ºfalse
        options.set_paths(browser_path=browser_path).headless(True)
    else:
        options.set_argument("--auto-open-devtools-for-tabs", "true")  # æ‰“å¼€æ§åˆ¶å°
        options.set_paths(browser_path=browser_path).headless(False)

    if proxy:
        options.set_proxy(proxy)

    driver = ChromiumPage(addr_or_opts=options)
    if init_js:
        driver.add_init_js(init_js)
    browser_cache[browser_id] = driver
    return driver


# Solve Cloudflare challenge
async def solve_cloudflare(page: ChromiumPage, retries: int = 5, log: bool = True) -> bool:
    try:
        cf_bypasser = CloudflareBypasser(page, retries, log)
        cf_bypasser.bypass()
        return True
    except Exception as e:
        sys_logger.error(f"Cloudflare bypass error: {str(e)}")
        return False


# ä¿®æ”¹è·å–æˆ–åˆ›å»ºé¡µé¢çš„å‡½æ•°ï¼Œå¤„ç†æµè§ˆå™¨è¿æ¥æ–­å¼€çš„æƒ…å†µ
async def get_or_create_page(page_key: str = None, browser_id: str = "default", url: str = None, init_js: str = None, init_cookie: Dict[str, str] | str = None, reset_cookie: Dict[str, str] | str = None, snapshot: bool = False):
    """
    è·å–æˆ–åˆ›å»ºé¡µé¢ï¼Œå¤„ç†é¡µé¢è¿æ¥æ–­å¼€ç­‰å¼‚å¸¸æƒ…å†µï¼Œè‡ªåŠ¨è§£å†³ Cloudflare æŒ‘æˆ˜
    """
    page = None
    is_new = False
    success = True
    error_msg = None
    browser = None

    # å°è¯•ä»ç¼“å­˜è·å–é¡µé¢
    if page_key and page_key in page_cache:
        page = page_cache[page_key]

        # æ£€æŸ¥é¡µé¢è¿æ¥æ˜¯å¦æ­£å¸¸
        try:
            # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ“ä½œæ¥æµ‹è¯•é¡µé¢è¿æ¥
            page.run_js('1+1')
        except Exception as e:
            sys_logger.info(f"æ£€æµ‹åˆ°é¡µé¢è¿æ¥å·²æ–­å¼€ï¼Œé‡æ–°åˆ›å»ºé¡µé¢: {str(e)}")
            # æ¸…ç†æ—§é¡µé¢
            cleanup_page(page, page_key, browser_id)
            # å°†é¡µé¢è®¾ä¸º Noneï¼Œä¸‹é¢ä¼šé‡æ–°åˆ›å»º
            page = None
            # ä»ç¼“å­˜ä¸­ç§»é™¤
            if page_key in page_cache:
                del page_cache[page_key]

    # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„é¡µé¢æˆ–é¡µé¢è¿æ¥å·²æ–­å¼€ï¼Œåˆ›å»ºæ–°é¡µé¢
    if page is None and url:
        is_new = True
        try:
            # æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦å­˜åœ¨ä¸”è¿æ¥æ­£å¸¸
            if browser_id in browser_cache:
                browser = browser_cache[browser_id]
                try:
                    # æµ‹è¯•æµè§ˆå™¨è¿æ¥
                    browser.run_js('1+1')
                except Exception as e:
                    sys_logger.info(f"æ£€æµ‹åˆ°æµè§ˆå™¨è¿æ¥å·²æ–­å¼€ï¼Œé‡æ–°åˆ›å»ºæµè§ˆå™¨: {str(e)}")
                    # ä»ç¼“å­˜ä¸­ç§»é™¤
                    if browser_id in browser_cache:
                        try:
                            browser_cache[browser_id].quit()
                        except:
                            pass
                        del browser_cache[browser_id]
                    browser = None

            # å¦‚æœæµè§ˆå™¨ä¸å­˜åœ¨æˆ–è¿æ¥æ–­å¼€ï¼Œåˆ›å»ºæ–°æµè§ˆå™¨
            if browser is None:
                proxy = next_proxy()
                browser = get_or_create_browser(browser_id, init_js=init_js,proxy=proxy)
            # åˆ›å»ºæ–°æ ‡ç­¾é¡µ
            page = browser.new_tab()
            page.set.blocked_urls([
                "*.png",
                "*.jpg",
                "*.jpeg",
                "*.gif",
                "*.svg",
                "*.ico",
                "*.webp",
                "*.txt",
                "*.pdf",
                "*.doc",
                "*.mp4",
                "*.webm",
                "*.avi",
                "*.m3u8",
                "*.mp3",
                "*.wav",
                "*.ogg",
                "*.flac",
                "*.aac",
                "*.m4a",
                "*.m4b",
                "*.m4p",
                "*.m4v",
            ])
            if init_cookie:
                page.set.cookies(init_cookie)
            if init_js:
                page.add_init_js(init_js)
            # å¯¼èˆªåˆ° URL
            page.get(url, timeout=10)

            # è‡ªåŠ¨å°è¯•è§£å†³ Cloudflare æŒ‘æˆ˜
            solved = await solve_cloudflare(page)
            if not solved:
                success = False
                error_msg = "ç»•è¿‡cloudflareå¤±è´¥"

                # å¦‚æœéœ€è¦æˆªå›¾
                if snapshot:
                    try:
                        os.makedirs('screenshot', exist_ok=True)
                        page.save_screenshot(f'screenshot/{urlparse(url).netloc}.png')
                        with open(f'screenshot/{urlparse(url).netloc}.html', "w", encoding="utf-8") as f:
                            f.write(page.html)
                    except Exception as e:
                        sys_logger.error(f"æˆªå›¾å¤±è´¥: {str(e)}")

                # æ¸…ç†èµ„æº
                cleanup_page(page, page_key, browser_id)
                page = None
            else:
                # å¦‚æœéœ€è¦ç¼“å­˜é¡µé¢
                if page_key:
                    page_cache[page_key] = page

        except Exception as e:
            success = False
            error_msg = f"åˆ›å»ºé¡µé¢å¤±è´¥: {str(e)}"
            if page:
                cleanup_page(page, page_key, browser_id)
                page = None

    if reset_cookie:
        page.set.cookies(reset_cookie)
    return page, is_new, success, error_msg


# New POST request endpoint
@app.post("/")
async def chrome_request(req: ChromeRequest):
    if not is_safe_url(req.url):
        raise HTTPException(status_code=400, detail="Invalid URL")

    # è·å–é¡µé¢ç¼“å­˜é”®
    page_key = f"{req.browser_id}_{req.page_id}" if req.page_id else None

    try:
        init_js =  """
Function.prototype.temp_constructor= Function.prototype.constructor;
Function.prototype.constructor=function(){
    if (arguments && typeof arguments[0]==="string"){
    if (arguments[0]==="debugger")
        return ""
    }
    return Function.prototype.temp_constructor.apply(this, arguments);
};
console.log('è¦†ç›–ådebuggeræˆåŠŸ');
window.__antijs=true;

"""
# window.setTimeout = (callback, delay) => {
#     return 0
# };
# console.log('è¦†ç›–setTimeoutæˆåŠŸ')
# window.setInterval = (callback, delay) => {
#     return 0
# };
# console.log('è¦†ç›–setIntervalæˆåŠŸ')
        # è·å–æˆ–åˆ›å»ºé¡µé¢
        page, is_new, success, error_msg = await get_or_create_page(
            page_key=page_key,
            browser_id=req.browser_id,
            url=req.url,
            init_cookie=req.cookies,
            reset_cookie=req.reset_cookie,
            snapshot=req.snapshot,
            init_js=init_js
        )

        if not success:
            return JSONResponse(
                                status_code=500,
                                content={"ok": False, "msg": error_msg}
                            )

        if not page:
            return JSONResponse(
                                status_code=500,
                                content={"ok": False, "msg": "Failed to create page"}
                            )

        # å¤„ç†è¯·æ±‚
        if not req.api_url:
            resp_data = page.html
            resp_obj = resp_data
        else:
            headers = {
                "accept": "*/*",
                "accept-language": "zh-CN,zh;q=0.9",
                "content-type": "application/json",
                "sec-ch-ua": '"Not?A_Brand";v="8", "Chromium";v="108", "Google Chrome";v="108"',
                "sec-ch-ua-mobile": "?0",
                "sec-ch-ua-platform": '"macOS"',
                "sec-fetch-dest": "empty",
                "sec-fetch-mode": "cors",
                "sec-fetch-site": "same-site"
            }

            for k, v in req.headers.items():
                headers[k.lower()] = v

            script = """
                async () => {
                    try {
                        let resp = await fetch("%s", {
                            "headers": %s,
                            "method": "%s",
                            "body": %s,
                            "referrer": "%s",
                            "referrerPolicy": "strict-origin-when-cross-origin", 
                            "mode": "cors",
                            "keepalive": true,
                            "credentials": "include"
                        });
                        return await resp.text();
                    } catch (e) {
                        return JSON.stringify({"error": e.toString()});
                    }
                }
            """ % (req.api_url, json.dumps(headers), req.method,
                   json.dumps(req.body) if req.body else "null", req.url)

            # æ‰“å°è¯·æ±‚ä¿¡æ¯
            sys_logger.info(f"API Request: {req.method} {req.api_url}")
            sys_logger.info(f"Headers: {json.dumps(headers)[:200]}{'...' if len(json.dumps(headers)) > 200 else ''}")
            if req.body:
                sys_logger.info(f"Body: {req.body[:200]}{'...' if len(req.body) > 200 else ''}")

            resp_data = page.run_js(script)

            # æ‰“å°å“åº”æ•°æ®
            sys_logger.info(f"API Response: {resp_data[:500]}{'...' if len(resp_data) > 500 else ''}")

            resp_obj = resp_data

            if "content-type" in headers and headers["content-type"].lower() == "application/json":
                try:
                    resp_obj = json.loads(resp_data)
                except Exception as e:
                    # è§£æ JSON å¤±è´¥ï¼Œæ¸…ç†èµ„æº
                    if not req.debug:
                        cleanup_page(page, page_key, req.browser_id)
                    return JSONResponse(
                                status_code=500,
                                content={"ok": False, "msg": f"é JSON æ•°æ®: {resp_data}"}
                            )

        # å¦‚æœä¸éœ€è¦ç¼“å­˜é¡µé¢ï¼Œåˆ™æ¸…ç†
        if not page_key:
            sys_logger.info('å…³é—­é¡µé¢', req.browser_id, req.browser_id not in browser_cache)
            cleanup_page(page, page_key, req.browser_id)

        return resp_obj

    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        sys_logger.error(f"Error in chrome_request: {error_trace}")

        # å¦‚æœéœ€è¦æˆªå›¾
        if req.snapshot and page:
            try:
                os.makedirs('screenshot', exist_ok=True)
                page.save_screenshot(f'screenshot/error_{urlparse(req.url).netloc}.png')
                with open(f'screenshot/error_{urlparse(req.url).netloc}.html', "w", encoding="utf-8") as f:
                    f.write(page.html)
            except Exception as screenshot_error:
                sys_logger.error(f"Error taking screenshot: {str(screenshot_error)}")

        # æ¸…ç†èµ„æº
        cleanup_page(page, page_key, req.browser_id)

        return JSONResponse(
            status_code=500,
            content={"ok": False, "msg": str(e), "trace": error_trace}
        )


from concurrent.futures import ThreadPoolExecutor
# å…¨å±€çº¿ç¨‹æ± ï¼ˆé¿å…é¢‘ç¹åˆ›å»ºé”€æ¯çº¿ç¨‹ï¼‰
_executor = ThreadPoolExecutor(max_workers=4)



async def async_eval_no_wait(code,page):
    """
    å®Œå…¨éé˜»å¡çš„evalæ‰§è¡Œ
    :param code: è¦æ‰§è¡Œçš„JSä»£ç 
    :param page: DrissionPageçš„ChromiumPageå®ä¾‹
    """
    # å‡†å¤‡æ‰§è¡Œç¯å¢ƒï¼ˆç¡®ä¿çº¿ç¨‹å®‰å…¨ï¼‰
    safe_vars = {
        'page': page,
        '__builtins__': {}  # ç¦ç”¨å±é™©å‡½æ•°
    }
    
    def execute_eval(code, variables):
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œevalä¸”ä¸å…³å¿ƒç»“æœ"""
        try:
            eval(code, variables, {})
        except Exception as e:
            print(f"âš ï¸ Evalæ‰§è¡Œå¤±è´¥ï¼ˆå·²å¿½ç•¥ï¼‰: {type(e).__name__}: {e}")

    # åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œï¼ˆä¸é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
    future = asyncio.get_event_loop().run_in_executor(
        _executor,
        execute_eval,
        code,
        safe_vars
    )
    
    # ç«‹å³è¿”å›æ§åˆ¶æƒ
    future.add_done_callback(
        lambda f: sys_logger.error(f"Evalæ“ä½œå¼‚å¸¸: {f.exception()}") if f.done() and f.exception() else print("ğŸ¯ Evalæ“ä½œå·²æäº¤åˆ°åå°çº¿ç¨‹") if f.done() else None
    )

async def setup_breakpoint_and_expose_function(page, chunk_url, line_number=0, column_number=0, target_func_name="targetFunction", export_func_name="exposedFunction", trigger_js=None):
    # æ³¨å…¥è¾…åŠ©å‡½æ•°
    # ----------- è¿™æ˜¯å…³é”®éƒ¨åˆ† - å°†æˆ‘ä»¬è¦æ‰¾çš„å‡½æ•°æš´éœ²åˆ°å…¨å±€ä½œç”¨åŸŸ ------------
    script = """
            console.log('ç›®æ ‡å‡½æ•°', """ + target_func_name + """);
            window.""" + export_func_name + """ = """ + target_func_name + """; 
            """
    if chunk_url == "":
        page.run_js(script)
        return

    # åˆå§‹åŒ– ws å˜é‡ä¸º Noneï¼Œç¡®ä¿åœ¨ finally å—ä¸­å¯ä»¥å®‰å…¨å¼•ç”¨
    ws = None

    target_info = page.run_cdp("Target.getTargetInfo")
    target_id = target_info.get('targetInfo', {}).get('targetId')
    if not target_id:
        sys_logger.error("æ— æ³•è·å–ç›®æ ‡ID")
        return False
    current_url = page.url
    print('current_url', current_url)
    # æ„å»ºWebSocket URL
    ws_url = f"ws://{page.address}/devtools/page/{target_id}"
    # sys_logger.info(f"è¿æ¥DevTools WebSocket: {ws_url}")
    try:
        # ç§»é™¤ timeout å‚æ•°ï¼Œä½¿å…¶å…¼å®¹ Python 3.10
        ws = await websockets.connect(ws_url)        # sys_logger.info("WebSocketè¿æ¥å·²æ‰“å¼€")
        # å¯ç”¨è°ƒè¯•å™¨
        await ws.send(json.dumps({
            "id": 1,
            "method": "Debugger.enable"
        }))
       
        # è®¾ç½®æ–­ç‚¹
        await ws.send(json.dumps({
            "id": 2,
            "method": "Debugger.setBreakpointByUrl",
            "params": {
                "url": chunk_url,
                "lineNumber": line_number,
                "columnNumber": column_number,
            }
        }))
        await ws.send(json.dumps({
            "id": 3,
            "method": "Page.enable"
        }))

        # if trigger_js:
            # page.run_js(trigger_js, as_expr=True)
        # print("ç›‘å¬æ¶ˆæ¯")
        # --- ç¬¬äºŒé˜¶æ®µï¼šç›‘å¬æ¶ˆæ¯ç›´åˆ°æ»¡è¶³æ¡ä»¶ ---
        trigger_received = False
        # è®°å½•å¼€å§‹æ—¶é—´
        trigger_js_executed = False
        
        start_wait_time = asyncio.get_event_loop().time()
        while not trigger_received:
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡3ç§’ä¸”è¿˜æ²¡æ‰§è¡Œè¿‡trigger_js
            has_wait = asyncio.get_event_loop().time()-start_wait_time
            if has_wait > 10:
                raise asyncio.TimeoutError("ç­‰å¾…æ–­ç‚¹è§¦å‘è¶…æ—¶ï¼Œæ€»ç­‰å¾…æ—¶é—´è¶…è¿‡5ç§’")

            if has_wait > 5 and not trigger_js_executed and trigger_js:
                await async_eval_no_wait(trigger_js, page)
                trigger_js_executed=True
            try:
                response = await asyncio.wait_for(ws.recv(), timeout=2)
            except asyncio.TimeoutError:
                # æ£€æŸ¥æ€»ç­‰å¾…æ—¶é—´æ˜¯å¦è¶…è¿‡5ç§’
                print('å·²ç­‰å¾…æ—¶é—´', has_wait)
                continue
            # print('æ”¶åˆ°æ¶ˆæ¯', response)
            
            # print(f"æ”¶åˆ°æ¶ˆæ¯: {response}")
            data = json.loads(response)
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–­ç‚¹æš‚åœäº‹ä»¶
            if data.get('method') == 'Debugger.paused':
                params = data.get('params', {})
                hit_breakpoints = params.get('hitBreakpoints', [])
                call_frame_id = params.get('callFrames', [])[0].get('callFrameId')

                if hit_breakpoints:
                    hit_id = hit_breakpoints[0]
                    trigger_received = True
                    # print(f"æ–­ç‚¹è§¦å‘", hit_id, call_frame_id)

                    await ws.send(json.dumps({
                        "id": 999,
                        "method": "Debugger.evaluateOnCallFrame",
                        "params": {
                            "callFrameId": call_frame_id,
                            "expression": script
                        }
                    }))
                    # ç§»é™¤æ–­ç‚¹
                    await ws.send(json.dumps({
                        "id": 1000,
                        "method": "Debugger.removeBreakpoint",
                        "params": {
                            "breakpointId": hit_id
                        }
                    }))
                    await ws.send(json.dumps({
                        "id": 1001,
                        "method": "Page.stopLoading",
                        "params": {}
                    }))
                    # print(f"æ³¨å…¥è¾…åŠ©å‡½æ•°", call_frame_id, script)
                    # # æ¢å¤æ‰§è¡Œ
                    await ws.send(json.dumps({
                        "id": 1002,
                        "method": "Debugger.resume",
                        "params": {}
                    }))
                    print('ç§»é™¤æ–­ç‚¹', hit_id)

            if data.get('method') == 'Page.frameNavigated':
                frame = data["params"]["frame"]
                url = frame.get("url", "")
                print('frameNavigated', url)
                if url != 'about:blank' and url != current_url:
                    print('stopLoading', url)
                    await ws.send(json.dumps({
                        "id": 1005,
                        "method": "Page.stopLoading",
                        "params": {}
                    }))
    except asyncio.TimeoutError:
        sys_logger.error("æ“ä½œè¶…æ—¶ï¼Œå¼ºåˆ¶å…³é—­è¿æ¥")
    except websockets.exceptions.ConnectionClosed as e:
        sys_logger.error(f"è¿æ¥å¼‚å¸¸å…³é—­: {e.code} {e.reason}")
    except Exception as e:
        sys_logger.error(f"æœªçŸ¥é”™è¯¯: {str(e)}")
    finally:
        # å®‰å…¨åœ°å…³é—­ WebSocket è¿æ¥
        if ws is not None:
            try:
                await ws.close()
            except Exception as e:
                sys_logger.error(f"å…³é—­ WebSocket è¿æ¥æ—¶å‡ºé”™: {str(e)}")

    return True


# APIè·¯ç”±
@app.get("/admin")
async def get_admin_page(username: str = Depends(verify_credentials)):
    with open('static/index.html', 'r', encoding='utf-8') as f:
        content = f.read()
    return HTMLResponse(content=content)

# æ–°å¢ antijs API è·¯ç”±


class AntiJsRequest(BaseModel):
    # cookiesæ ¼å¼ 'name1=value1; name2=value2; path=/; domain=.example.com;'
    cookies: Dict[str, str]|str = Field(None) # init_cookieï¼Œ ç¬¬ä¸€æ¬¡æ‰ä¼šé‡ç½®
    reset_cookie: Dict[str, str]|str = Field(None) # æ¯æ¬¡éƒ½ä¼šé‡ç½®
    data: Any


@app.post("/api/antijs/{api_name}")
@limiter.limit("10/second", key_func=lambda request: f"api:{request.path_params['api_name']}")
async def anti_js(api_name: str, data: AntiJsRequest, request: Request):
    """æ¥æ”¶æ•°æ®å¹¶æ ¹æ®APIåç§°å¤„ç†"""
    # ä»è¯·æ±‚å¯¹è±¡ä¸­è·å–request_idï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç”Ÿæˆä¸€ä¸ªæ–°çš„
    request_id = request.state.request_id if hasattr(request.state, "request_id") else str(uuid.uuid4())
    is_debug = request.headers.get('debug', False)

    # ä¿å­˜åˆ°è¯·æ±‚å¯¹è±¡ä¸­ï¼Œç¡®ä¿ä¸­é—´ä»¶å¯ä»¥è®¿é—®åˆ°
    request.state.request_id = request_id

    # åˆ›å»ºè¯·æ±‚ä¸Šä¸‹æ–‡çš„logger
    log = logger.bind(request_id=request_id)

    # è®°å½•è¯·æ±‚å¼€å§‹
    log.info(f"/antijs/{api_name}")

    start_time = datetime.now()
    page = None  # åˆå§‹åŒ– page å˜é‡ä¸º None
    page_key = None  # åˆå§‹åŒ– page_key å˜é‡ä¸º None
    browser_id = "default"  # è®¾ç½®é»˜è®¤ browser_id

    try:
        # ä»å†…å­˜ä¸­è·å–é…ç½®
        config = website_configs.get_by_api_name(api_name)
        if not config:
            # é…ç½®ä¸å­˜åœ¨ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            return JSONResponse(
                status_code=200,
                content={"code": 1, "msg": "APIä¸å­˜åœ¨"}
            )

        # # æ£€æŸ¥å‚æ•°é•¿åº¦é™åˆ¶ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
        # if config.get('params_len') is not None and len(data.data) != config['params_len']:
        #     log.error(f"å‚æ•°é•¿åº¦ä¸åŒ¹é…ï¼Œåº”ä¸º {config['params_len']}ï¼Œå®é™…ä¸º {len(data.data)}")
        #     return JSONResponse(
        #         status_code=200,
        #         content={"code": 1, "msg": f"å‚æ•°é•¿åº¦ä¸åŒ¹é…ï¼Œåº”ä¸º {config['params_len']}ï¼Œå®é™…ä¸º {len(data.data)}"}
        #     )

        # æ£€æŸ¥é…ç½®æ˜¯å¦è¿‡æœŸ
        if config.get('expire_time'):
            expire_time = config['expire_time']
            if isinstance(expire_time, str):
                expire_time = datetime.strptime(expire_time, '%Y-%m-%d %H:%M:%S')
            if datetime.now() > expire_time:
                log.error("APIå·²è¿‡æœŸ")
                return JSONResponse(
                    status_code=200,
                    content={"code": 1, "msg": "APIå·²è¿‡æœŸ"}
                )

        # æ£€æŸ¥æœ€å¤§è°ƒç”¨æ¬¡æ•°é™åˆ¶
        if config.get('max_calls') is not None:
            # ä½¿ç”¨Redisè·Ÿè¸ªAPIè°ƒç”¨æ¬¡æ•°
            redis_client = get_redis_client()

            if redis_client:
                # ä½¿ç”¨api_nameä½œä¸ºRedisé”®çš„ä¸€éƒ¨åˆ†
                redis_key = f"{redis_prefix}call_count:{api_name}"

                # è·å–å½“å‰è°ƒç”¨æ¬¡æ•°
                current_count = redis_client.get(redis_key)
                current_count = int(current_count) if current_count else 0

                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è°ƒç”¨æ¬¡æ•°
                if current_count >= config['max_calls']:
                    log.error("å¯ç”¨æ¬¡æ•°å·²ç”¨å®Œ")
                    return JSONResponse(
                        status_code=200,
                        content={"code": 1, "msg": "å¯ç”¨æ¬¡æ•°å·²ç”¨å®Œ"}
                    )

                # å¢åŠ è°ƒç”¨è®¡æ•°ï¼ˆä½¿ç”¨pipelineç¡®ä¿åŸå­æ€§ï¼‰
                pipe = redis_client.pipeline()
                pipe.incr(redis_key)
                # é»˜è®¤30å¤©åè¿‡æœŸï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
                pipe.expire(redis_key, 60 * 60 * 24 * 30)

                # æ‰§è¡ŒRediså‘½ä»¤
                pipe.execute()

        # å¯¹source_websiteåšMD5å¤„ç†
        page_key = hashlib.md5(config['source_website'].encode()).hexdigest()

        init_js = """
Function.prototype.temp_constructor= Function.prototype.constructor;
Function.prototype.constructor=function(){
    if (arguments && typeof arguments[0]==="string"){
    if (arguments[0]==="debugger")
        return ""
    }
    return Function.prototype.temp_constructor.apply(this, arguments);
};
console.log('è¦†ç›–ådebuggeræˆåŠŸ')
        """
        init_js += "window.__antijs=true;"
        if not config.get('override_funcs'):
            config['override_funcs'] = 'all'
        for method in config['override_funcs'].split(','):
            if method == 'all' or method == 'setTimeout':
                init_js += """
window.setTimeout = (callback, delay) => {
    return 0
};
console.log('è¦†ç›–setTimeoutæˆåŠŸ')
"""
            if method == 'all' or method == 'setInterval':
                init_js += """
window.setInterval = (callback, delay) => {
    return 0
};
console.log('è¦†ç›–setIntervalæˆåŠŸ')
"""

        cookies = data.cookies
        if not cookies:
            cookies = config.get('cookies')
        # è·å–æˆ–åˆ›å»ºé¡µé¢
        page, is_new, success, error_msg = await get_or_create_page(
            page_key=page_key,
            browser_id=browser_id,
            init_js=init_js,
            init_cookie=cookies,
            reset_cookie=data.reset_cookie,
            url=config['source_website'] if not page_key in page_cache else None
        )

        if not success:
            log.error(f"é¡µé¢åˆ›å»ºå¤±è´¥: {error_msg}, open website failed: {config['source_website']}", )
            return JSONResponse(
                status_code=200,
                content={"code": 1, "msg": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}
            )

        if not page:
            log.error("é¡µé¢ä¸ºç©º")
            return JSONResponse(
                status_code=200,
                content={"code": 1, "msg": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}
            )

        inject_func_name = "___" + api_name
        # æ£€æŸ¥å‡½æ•°æ˜¯å¦å­˜åœ¨
        check_script = """typeof window.""" + inject_func_name + """ === 'function'"""
        injected = page.run_js(check_script, as_expr=True, timeout=1)
        if not injected:
            await setup_breakpoint_and_expose_function(page, config['hijack_js_url'], line_number=config['breakpoint_line_num'], column_number=config['breakpoint_col_num'], target_func_name=config['target_func'], export_func_name=inject_func_name, trigger_js=config['trigger_js'])
            injected = page.run_js(check_script, as_expr=True, timeout=1)
        if not injected:
            log.error(f"å‡½æ•°æ³¨å…¥å¤±è´¥")
            if not is_debug:
                cleanup_page(page, page_key, browser_id)
            return JSONResponse(
                status_code=500,
                content={"code": 1, "msg": "è°ƒç”¨å¤±è´¥, è¯·ç¨åé‡è¯•ã€‚å¦‚ä¸€ç›´ä¸æˆåŠŸ, è¯·è”ç³»ç®¡ç†å‘˜"}
            )

        sign_script = """
            async () => {
                try {
                    // è°ƒç”¨å‡½æ•°
                    const result = await window.""" + inject_func_name + """(%s);
                    return result;
                } catch (e) {
                    return {"__error__": e.toString()};
                }
            }
        """ % (json.dumps(data.data))

        sign_result = page.run_js(sign_script, timeout=5)

        # æ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«é”™è¯¯
        if isinstance(sign_result, dict) and '__error__' in sign_result:
            log.error(f"æ‰§è¡Œè„šæœ¬å‡ºé”™: {sign_result['__error__']}")
            return JSONResponse(
                status_code=200,
                content={"code": 1, "msg": "è°ƒç”¨å¤±è´¥, ç›®æ ‡å‡½æ•°æŠ¥é”™: " + sign_result['__error__']}
            )

        # è®¡ç®—è¯·æ±‚å¤„ç†æ—¶é—´
        elapsed_time = (datetime.now() - start_time).total_seconds() * 1000
        log.info(f"succ, elapsed[{elapsed_time:.2f}ms]")

        # è¿”å› API è°ƒç”¨ç»“æœå’Œç­¾åä¿¡æ¯
        return JSONResponse(
            status_code=200,
            content={"code": 0, "msg": "æˆåŠŸ", "data": sign_result}
        )

    except Exception as e:
        # è®¡ç®—è¯·æ±‚å¤„ç†æ—¶é—´
        elapsed_time = (datetime.now() - start_time).total_seconds() * 1000
        # æ¸…ç†èµ„æºï¼ˆåªæœ‰å½“ page ä¸ä¸º None æ—¶æ‰æ¸…ç†ï¼‰
        if page:
            cleanup_page(page, page_key, browser_id)

        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
        import traceback
        error_trace = traceback.format_exc()
        log.error(f"å¤„ç†è¯·æ±‚å¼‚å¸¸ | è€—æ—¶: {elapsed_time:.2f}ms | é”™è¯¯: {str(e)}\n{error_trace}")

        return JSONResponse(
            status_code=200,
            content={"code": 1, "msg": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}
        )


# æ·»åŠ ä¸¤ä¸ªæ–°çš„APIæ¥å£åˆ°internal_api.pyä¸­
@internal_api_router.get("/api/page_status")
async def get_page_status(username: str = Depends(verify_credentials)):
    """è·å–æ¯ä¸ªAPIå¯¹åº”çš„é¡µé¢çŠ¶æ€"""
    # è·å–æ‰€æœ‰é…ç½®
    configs = await list_configs(username)

    # æ„é€ ç»“æœå­—å…¸
    result = {}
    for config in configs:
        api_name = config.get('api_name')
        if api_name:
            # æ£€æŸ¥é¡µé¢æ˜¯å¦åœ¨ç¼“å­˜ä¸­
            # å¯¹source_websiteåšMD5å¤„ç†ï¼Œä¸anti_jsè·¯ç”±ä¸­çš„å¤„ç†æ–¹å¼ä¸€è‡´
            page_key = hashlib.md5(config['source_website'].encode()).hexdigest()
            is_page_open = page_key in page_cache
            result[api_name] = {
                "is_page_open": is_page_open,
                "page_key": page_key if is_page_open else None
            }

    return result


@internal_api_router.post("/api/close_page/{api_name}")
async def close_page(api_name: str, username: str = Depends(verify_credentials)):
    """å…³é—­æŒ‡å®šAPIåç§°å¯¹åº”çš„é¡µé¢"""
    # è·å–APIå¯¹åº”çš„é…ç½®
    db = get_db_session()
    if not db:
        return {"success": False, "message": "æ•°æ®åº“è¿æ¥å¤±è´¥"}

    try:
        config = db.query(AntiJsConfig).filter(AntiJsConfig.api_name == api_name).first()
        if not config:
            return {"success": False, "message": "æ‰¾ä¸åˆ°å¯¹åº”çš„APIé…ç½®"}

        # å¯¹source_websiteåšMD5å¤„ç†ï¼Œä¸anti_jsè·¯ç”±ä¸­çš„å¤„ç†æ–¹å¼ä¸€è‡´
        page_key = hashlib.md5(config.source_website.encode()).hexdigest()
        browser_id = "default"

        # æ£€æŸ¥é¡µé¢æ˜¯å¦åœ¨ç¼“å­˜ä¸­
        if page_key in page_cache:
            # è·å–é¡µé¢å¯¹è±¡
            page = page_cache[page_key]
            # å…³é—­é¡µé¢
            cleanup_page(page, page_key, browser_id)
            return {"success": True, "message": f"æˆåŠŸå…³é—­ {api_name} çš„é¡µé¢"}
        else:
            return {"success": False, "message": "é¡µé¢æœªæ‰“å¼€æˆ–å·²å…³é—­"}
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        return {"success": False, "message": f"å…³é—­é¡µé¢æ—¶å‡ºé”™: {str(e)}", "error": error_trace}

# ä¿®æ”¹ç°æœ‰çš„configsæ¥å£ï¼Œè¿”å›é¡µé¢çŠ¶æ€


@internal_api_router.get("/api/configs")
async def list_configs(username: str = Depends(verify_credentials)):
    db = get_db_session()
    if not db:
        raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")

    configs = []
    try:
        # æŸ¥è¯¢é…ç½®åˆ—è¡¨
        db_configs = db.query(AntiJsConfig).order_by(AntiJsConfig.id.desc()).all()

        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        for config in db_configs:
            config_dict = {
                "id": config.id,
                "api_name": config.api_name,
                "user_name": config.user_name,
                "source_website": config.source_website,
                "hijack_js_url": config.hijack_js_url,
                "breakpoint_line_num": config.breakpoint_line_num,
                "breakpoint_col_num": config.breakpoint_col_num,
                "target_func": config.target_func,
                "params_len": config.params_len,
                "params_example": config.params_example,
                "expire_time": config.expire_time.strftime('%Y-%m-%d %H:%M:%S') if config.expire_time else None,
                "max_calls": config.max_calls,
                "is_active": config.is_active,
                "description": config.description,
                "override_funcs": config.override_funcs,
                "trigger_js": config.trigger_js,
                "cookies": config.cookies
            }

            # è·å–è°ƒç”¨æ¬¡æ•°
            redis_client = get_redis_client()
            if redis_client and config.max_calls:
                redis_key = f"{redis_prefix}call_count:{config.api_name}"
                call_count = redis_client.get(redis_key)
                call_count = int(call_count) if call_count else 0
                config_dict["call_count"] = call_count
                # è®¡ç®—ä½¿ç”¨ç™¾åˆ†æ¯”
                config_dict["call_percentage"] = min(100, round(call_count / config.max_calls * 100, 2))

            # æ·»åŠ é¡µé¢çŠ¶æ€ä¿¡æ¯
            page_key = hashlib.md5(config.source_website.encode()).hexdigest()
            config_dict["is_page_open"] = page_key in page_cache
            config_dict["page_key"] = page_key

            configs.append(config_dict)

        return configs
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢é…ç½®åˆ—è¡¨å¤±è´¥: {str(e)}")


inject_apis = [
    {
        'id': 99999,  # ä½¿ç”¨ä¸€ä¸ªç‰¹åˆ«çš„IDä»¥é¿å…å†²çª
        'api_name': 'debank_sign',
        'user_name': 'system',
        'source_website': 'https://debank.com/profile/0x3fe861679bd8ec58dd45460ffd38ee39107aaff8/history',
        'hijack_js_url': 'https://assets.debank.com/static/js/6129.fbaacfcf.chunk.js',
        'breakpoint_line_num': 1,
        'breakpoint_col_num': 45819,
        'target_func': 'x',
        'params_len': 4,  # è¯·æ±‚æ–¹æ³•ã€è·¯ç”±ã€æ•°æ®
        'params_example': """[
  {
            "user_addr":"0x3fe861679bd8ec58dd45460ffd38ee39107aaff8",
            "chain": "",
            "start_time": 0,
            "page_count": 20
        },
  "GET",
  "/history/list",
  {"version": "v2"}
]""",
        'expire_time': None,  # æ°¸ä¸è¿‡æœŸ
        'max_calls': None,  # æ— è°ƒç”¨æ¬¡æ•°é™åˆ¶
        'is_active': True,
        'description': 'è‡ªåŠ¨æ³¨å…¥çš„debankç­¾åAPI, æœç´¢"gsD"',
        'override_funcs': 'setTimeout,setInterval',
        'trigger_js': None,
        'cookies': None,
    },
    {
        'id': 100000001,  
        'api_name': 'jdsign',
        'user_name': 'system',
        # 'source_website': 'https://item.jd.com/1503764080.html',
        'source_website': 'https://www.jd.com/?country=USA',
        'hijack_js_url': '',
        'breakpoint_line_num': 0,
        'breakpoint_col_num': 0,
        'target_func': """
async (data) => {
    a = {
      appid: data.appid,
      clientVersion: data.clientVersion,
      client: data.client,
      t: data.t,
      body: SHA256(JSON.stringify(data.body)),
      functionId: data.functionId
    }
    result = await window.PSign.sign(a)
    return result
}
""",
        'params_example': """{
    "appid": "item-v3",
    "clientVersion": "1.0.0",
    "client": "pc",
    "t": 1763152375461,
    "body": {
        "testbody": "test"
    },
    "functionId": "pcCart_jc_buyNow"
}""",
        'expire_time': None,  # æ°¸ä¸è¿‡æœŸ
        'max_calls': None,  # æ— è°ƒç”¨æ¬¡æ•°é™åˆ¶
        'is_active': True,
        'description': 'äº¬ä¸œç­¾å',
        'override_funcs': 'setInterval',
        'trigger_js': None,
        'cookies': None,
        # 'cookies':{'name': 'flash', 'value': '3_ftSo4kyrbfy8JKAtEWdA7eLw1UPJQ6XkVcx1w2F7hOWlyrYmX4mtYmfZcVwbCcStW65woXYLPn-ysdqQKNRfYomKI6igPPUv3Aw6d8TAuwX8DHWGGQuQWm7p5oh2h8dS1cf2MBtHaG5Ru9XsGMDSTFegZoIK-1CbkxDTLkuxQX0uysdlyJslmq**', 'domain': '.jd.com',},
    },
    {
        'id': 100000002,  
        'api_name': 'okx_sign',
        'user_name': 'system',
        'source_website': 'https://web3.okx.com/zh-hans/token?hmi=500&pt=1&rb=8&tama=48&utmi=50&vmi=1000',
        'hijack_js_url': 'https://web3.okx.com/cdn/assets/okfe/util/ont/5.8.35/ont.js',
        'breakpoint_line_num': 0,
        'breakpoint_col_num': 143091,
        'target_func': """
async (data) => {
    return await no.getTokenAndSign({
                                url: data.url,
                                fetchConfig: data.fetchConfig,
                                ontConfig: i
                            });
}
""",
        'params_example': """{
    "url": "/priapi/v1/dx/market/v3/advanced/ranking/content?chainId=all&changePeriod=1&desc=true&holdersMin=500&inflowPeriod=1&liquidityMin=5000&openSource=false&periodType=1&riskFilter=true&stableTokenFilter=true&tradeNumPeriod=1&txsPeriod=1&volumeMin=1000&volumePeriod=1&categoryType=4&rankBy=8&tokenAgeType=2&pageSize=30&page=1&uniqueTraderMin=50&tokenAgeMax=48&totalPage=2&uniqueTraderPeriod=1&mentionedPeriod=1&t=1765274109486",
    "fetchConfig": {
        "method": "get"
    }
}""",
        'expire_time': None,  # æ°¸ä¸è¿‡æœŸ
        'max_calls': None,  # æ— è°ƒç”¨æ¬¡æ•°é™åˆ¶
        'is_active': True,
        'description': '',
        'override_funcs': 'setTimeout,setInterval',
        'trigger_js': None,
        'cookies': None,
    },

]

def inject_website_configs():
    """é¢„æ³¨å…¥å†…éƒ¨jsåˆ°website_configsä¸­"""
    for api in inject_apis:
        website_configs.set(api["api_name"], api)
    print(f"å†…éƒ¨jså·²æ³¨å…¥åˆ°website_configsä¸­")


# Main entry point
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Cloudflare bypass api")

    parser.add_argument("--nolog", action="store_true", help="Disable logging")
    parser.add_argument("--headless", action="store_true", help="Run in headless mode")
    parser.add_argument("--config", type=str, help="Path to config file")

    args = parser.parse_args()
    display = None

    if args.headless or DOCKER_MODE:
        # display = Display(visible=0, size=(1920, 1080))
        # ä½¿ç”¨æœ€å°çš„å±å¹•å°ºå¯¸å’Œæœ€ä½çš„è‰²å½©æ·±åº¦æ¥å‡å°‘å†…å­˜å ç”¨
        # æ·»åŠ é¢å¤–å‚æ•°ç¦ç”¨ä¸å¿…è¦çš„Xæ‰©å±•å’ŒåŠŸèƒ½
        display = Display(
            visible=0,
            size=(1, 1),  # ä½¿ç”¨æœ€å°å¯èƒ½çš„å°ºå¯¸
            color_depth=8,  # ä½¿ç”¨æœ€ä½çš„è‰²å½©æ·±åº¦
            extra_args=['-nolisten', 'tcp', '-noreset', '-nocursor']  # ç¦ç”¨ä¸å¿…è¦çš„åŠŸèƒ½
        )
        # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜ä½¿ç”¨
        os.environ['XVFB_SCREEN_DEPTH'] = '8'
        os.environ['XVFB_SCREEN'] = '1x1x8'
        display.start()

        def cleanup_display():
            if display:
                display.stop()
        atexit.register(cleanup_display)

    if args.nolog:
        log = False
    else:
        log = True

    server_port = 8889
    if args.config:
        # åˆå§‹åŒ–æ•°æ®åº“å’Œç¼“å­˜
        sys_logger.info(f'é…ç½®æ–‡ä»¶è·¯å¾„: {args.config}')
    init_database_and_cache(args.config)
    # è·å–æœåŠ¡å™¨ç«¯å£
    config = load_config(args.config)
    server_port = config['server']['port'] if config and 'server' in config else 8889

    # é¢„æ³¨å…¥é…ç½®åˆ°website_configsä¸­
    inject_website_configs()

    uvicorn.run(app, host="0.0.0.0", port=server_port)

# æ³¨å…¥debanké…ç½®çš„å‡½æ•°
